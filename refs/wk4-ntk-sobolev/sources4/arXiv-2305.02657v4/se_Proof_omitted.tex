\paragraph{Proof of \cref{prop:NN_Gen}}
% \begin{proof}[Proof of \cref{thm:NN_Gen}]
\cref{thm:NTK_EDR} shows the eigenvalue decay rate of $\NTK$ is $(d+1)/d$.
Therefore, the results in \citet{lin2018_OptimalRates} implies the lower rate and that the gradient flow of NTK satisfies
\begin{align}
  \label{eq:E_Proof1}
  \norm{\hat{f}^{\mathrm{NTK}}_{t_{\mathrm{op}}} - f^*}_{L^2} \leq C \left( \ln\frac{6}{\delta} \right) n^{-\frac{1}{2}\frac{s\beta}{s\beta + 1}}
\end{align}
with probability at least $1-\delta$, where $\beta = (d+1)/d$.

On the other hand, since $\mu$ is sub-Gaussian, $\sum_{i=1}^n \norm{x_i}_2 \leq C n^2$
for probability at least $1-\delta$ if $n \geq \mathrm{poly}(\ln(1/\delta))$.
From $y_i = f^*(\x_i) + \ep_i$, $f^* \in L^\infty$ and $\ep_i$ is sub-Gaussian,
we have $\norm{\bm{y}} \leq 2C n$ for probability at least $1-\delta$ as long as $n \geq \mathrm{poly}(\ln(1/\delta))$.
Then, taking $k=1/48$ and $r = m^{k}$ in \cref{lem:UnifConverge},
when $m \geq \mathrm{poly}(n,\lambda_0^{-1},\ln(1/\delta))$,
with probability $1-3\delta$ we have
\begin{align*}
  \sup_{t\geq 0} \sup_{\x \in B_r} \abs{\fNTK(\x) - \fNN(\x)} \leq C m^{-\frac{1}{24}}\sqrt {\ln m} \leq C n^{-1}
\end{align*}
as long as we take a larger power of $n$ in the requirement of $m$.
Consequently,
\begin{align*}
  \norm{(\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}} - f^*)\bm{1}_{B_n}}_{L^2}
  \leq \norm{(\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}} - \hat{f}^{\mathrm{NTK}}_{t_{\mathrm{op}}})\bm{1}_{B_n}}_{L^2} + \norm{(\hat{f}^{\mathrm{NTK}}_{t_{\mathrm{op}}} - f^*)\bm{1}_{B_n}}_{L^2}
  \leq  \frac{1}{n} + C \left( \ln\frac{12}{\delta} \right) n^{-\frac{1}{2}\frac{s\beta}{s\beta + 1}}.
\end{align*}
Now,
\begin{align*}
  \norm{\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}} - f^*}_{L^2}
&\leq \norm{(\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}} - f^*)\bm{1}_{B_n}}_{L^2}
  + \norm{\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}}\bm{1}_{B_n^\complement}}_{L^2}
  + \norm{f^* \bm{1}_{B_n^\complement}}_{L^2},
\end{align*}
where the first term is already bounded.
Noticing that $\mu$ is sub-Gaussian and $r = m^{1/48}$, by \cref{cor:UpperboundNN} we bound the second term by
\begin{align*}
  \norm{\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}}\bm{1}_{B_r^\complement}}_{L^2}
  \leq \norm{C m \norm{\tilde{x}} \bm{1}_{B_r^\complement}}_{L^2}
  \leq C m^{-1} \leq Cn^{-1}
\end{align*}
and the third term by
\begin{align*}
  \norm{f^* \bm{1}_{B_r^\complement}}_{L^2} \leq \norm{f^*}_{L^\infty} \mu(B_r^\complement)^{1/2} \leq C n^{-1}.
\end{align*}
Plugging these bounds into the above inequality, we finish the proof.

% \end{proof}

%\begin{proof}[Proof of \cref{prop:NN_Sup_Gen}]
%  The proof is similar to the previous one, except that we replace \cref{eq:E_Proof1} with
%  \begin{align*}
%    \norm{\hat{f}^{\mathrm{GF}}_{t_{\mathrm{op}}} - f^*}_{\infty}
%    \leq \kappa \norm{\hat{f}^{\mathrm{GF}}_{t_{\mathrm{op}}} - f^*}_{\caH} \leq C \left( \ln\frac{12}{\delta} \right) n^{-\frac{1}{2}\frac{(s-1)\beta}{s\beta + 1}},
%  \end{align*}
%  and replace \cref{eq:E_Proof2} by
%  \begin{align*}
%    \abs{\norm{\hat{f}^{\mathrm{NN}}_{t_{\mathrm{op}}} - f^*}_{\infty} - \norm{\fNTK - f^*}_{\infty}} \leq \frac{1}{n},
%  \end{align*}
%  which is a direct consequence of \cref{thm:UnifConverge}.
%\end{proof}

\subsection{Choosing stopping time with cross validation}
%We further assume that $y \in [-M,M]$ almost surely for some $M$ and introduce the truncation $L_{M}(a)=\min\{|a|,M\}\operatorname{sgn}(a)$.
%We are given $\tilde{n}$ extra independent samples $(\tilde{\x}_1,\tilde{y}_1),\dots,(\tilde{\x}_{\tilde{n}},\tilde{y}_{\tilde{n}})$,
%where $\tilde{n} \geq c n$ for some constant $c > 0$.
Before proving \cref{prop:NN_CV}, we introduce a modified version of \citet[Theorem 3]{caponnetto2010_CrossvalidationBased}.
\begin{proposition}
  \label{prop:E_CV}
  Let $\delta \in (0,1)$ and $\ep > 0$.
  Suppose $\hat{f}_t$ is a family of estimators indexed by $t \in T_n$ such that with probability at least $1-\delta$,
  it holds that $\norm{\hat{f}_{t_n} - f^*}_{L^2} \leq \ep$ for some $t_n \in T_n$.
  Then, by choosing  $\hat{t}_{\mathrm{cv}}$ by cross validation
  \cref{eq:5_StoppingTimeCV}, with probability at least $1-2\delta$, it holds that
  \begin{align}
    \norm{\hat{f}_{\hat{t}_{\mathrm{cv}}} - f^*}_{L^2} \leq 2\ep + \left( \frac{160 M^2}{\tilde{n}} \ln \frac{2\abs{T_n}}{\delta} \right)^{1/2}.
  \end{align}
\end{proposition}

\paragraph{Proof of \cref{prop:NN_CV}}
% \begin{proof}[Proof of \cref{thm:NN_CV}]
The choice of $T_n$ guarantees that there is $t_n \in T_n$
such that $t_{\mathrm{op}} \leq t_n \leq Q t_{\mathrm{op}}$ for $t_{\mathrm{op}} = n^{(d+1)/ [s(d+1)+d]}$
and that $\abs{T_n} \leq \log_Q n + 1 \leq C\ln n$.
Then, by \cref{prop:NN_Gen} we know that
\begin{align*}
  \norm{\hat{f}_{t_n} - f^*}_{L^2} \leq C \left( \ln\frac{12}{\delta} \right) n^{-\frac{1}{2}\frac{s\beta}{s\beta + 1}}.
\end{align*}
Consequently, by \cref{prop:E_CV}, we conclude that
\begin{align*}
  \norm{\hat{f}_{\hat{t}_{\mathrm{cv}}} - f^*}_{L^2}
  \leq C \left( \ln\frac{12}{\delta} \right) n^{-\frac{1}{2}\frac{s\beta}{s\beta + 1}}
  + \left( \frac{160 M^2}{c_{\mathrm{v}} n} \ln \frac{C \ln n}{\delta} \right)^{1/2}
  \leq C \left( \ln\frac{12}{\delta} \right) n^{-\frac{1}{2}\frac{s\beta}{s\beta + 1}}
\end{align*}
as long as $n$ is sufficiently large.
% \end{proof}