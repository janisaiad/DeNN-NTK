%!TEX root = main.tex

In this paper, we have analyzed the approximation properties of deep networks in kernel regimes, by studying eigenvalue decays of integral operators through differentiability properties of the kernel function.
In particular, the decay is governed by the form of the function's (generalized) power series expansion around~$\pm 1$, which remains the same for kernels arising from fully-connected ReLU networks of varying depths.
This result suggests that the kernel approach is unsatisfactory for understanding the power of depth in fully-connected networks.
In particular, it highlights the need to incorporate other regimes in the study of deep networks, such as the mean field regime~\citep{chizat2018global,mei2018mean}, and other settings with hierarchical structure~\citep[see, \eg,][]{allen2020backward,chen2020towards}.
We note that our results do not rule out benefits of depth for other network architectures in kernel regimes; for instance, depth may improve stability properties of convolutional kernels~\citep{bietti2019group,bietti2019inductive}, and a precise study of approximation for such kernels and its dependence on depth would also be of interest.