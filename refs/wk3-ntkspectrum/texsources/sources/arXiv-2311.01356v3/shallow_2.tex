

\label{sec:shallow}
Firstly, we consider shallow neural networks, i.e., networks that only have a single hidden layer and can hence be written as
\begin{equation*}
\left(x \mapsto (W^{(1)} \cdot x + b^{(1)})\right) \circ \relu \circ \left( x \mapsto (W^{(0)}\cdot x + b^{(0)}) \right).
\end{equation*}
As already explained above, we are from now on going to assume that the matrix $W^{(0)}$ and the vector $b^{(0)}$ are fixed and only assume randomness in $W^{(1)}$ and $b^{(1)}$.
\begin{lemma} \label{lem:scalarproduct_alternative_form}
Let $W^{(0)} \in \RR^{N \times d}$ and $b^{(0)} \in \RR^N$ be fixed. We recall that for $\alpha \in \RR^{d+1}$ we define
\begin{equation*}
f_\alpha: \quad \RR^{d+1} \to \{0,1\}, \quad x \mapsto \mathbbm{1}_{\alpha^Tx > 0}.
\end{equation*}
Furthermore, for any vector $z \in \RR^{d}$, let
\begin{equation*}
\tau_{\alpha, z} \defeq (W^{(0)}z) \odot \left( f_\alpha\left((W^{(0)}_{1,-}, b^{(0)}_1)^T\right) , ..., f_\alpha \left((W^{(0)}_{N,-}, b^{(0)}_N)^T\right)\right) \in \RR^N.
\end{equation*}
Then the following two statements hold:
\begin{enumerate}
\item{$Y_{z,x}=  \tau_{(x,1)^T, z}$ for every $x \in \RR^d$ and $z \in \B_d(0,1)$,}
\item{\label{item:lem_2}$\Vert \tau_{\alpha,z} \Vert_2 \leq \Vert W^{(0)} \Vert_2 \cdot \Vert z \Vert_2$ for all $\alpha \in \RR^{d+1}, z \in \RR^d$.}
\end{enumerate}
Here, $Y_{z,x}$ is as introduced in \Cref{prop:key}.
\end{lemma}

\begin{proof}
\leavevmode
\begin{enumerate}
\item{ Let $x \in \RR^d$ and $z \in \B_d(0,1)$. For every $i \in \{1,...,N\}$ we calculate
\begin{align*}
(D^{(0)}(x) \cdot W^{(0)} \cdot z)_i &= \mathbbm{1}_{W^{(0)}_{i,-} x + b^{(0)}_i > 0} \cdot \left(W^{(0)}z\right)_i \\
&= \left(W^{(0)}z\right)_i \cdot f_{(x,1)^T}\left(\left(W^{(0)}_{i,-}, b^{(0)}_i\right)^T\right) = \left(\tau_{(x,1)^T,z}\right)_i,
\end{align*}
which yields the claim.}
\item{It is immediate that
\begin{equation*}
\Vert \tau_{\alpha, z} \Vert_2 \leq \Vert W^{(0)}z \Vert_2 \cdot \underset{i=1,...,N}{\max} \underbrace{\abs{f_\alpha\left(\left(W^{(0)}_{i,-}, b^{(0)}_i\right)^T\right)}}_{\leq 1} \leq \Vert W^{(0)} \Vert_2 \cdot \Vert z \Vert_2. \qedhere
\end{equation*}
}
\end{enumerate}
\end{proof}

The desired bound for the covering number of $\mathcal{L}$ in the case of shallow networks is contained in the following lemma. 
\begin{lemma} \label{lem:cov_num_bound}
Assume that $W^{(0)} \in \RR^{N \times d}$ and $b^{(0)} \in \RR^N$ are fixed. There exists an absolute constant $C>0$ such that, writing $k \defeq \rang(W^{(0)})$, for every $\varepsilon \in (0, \Vert W^{(0)} \Vert_2)$ it holds
\begin{equation*}
\mathcal{N}(\mathcal{L}, \Vert \cdot \Vert_2, \eps) \leq \left(\frac{9 \Vert W^{(0)} \Vert_2}{\varepsilon}\right)^{C\cdot k}.
\end{equation*}
Here, $\mathcal{L}$ is as introduced in \Cref{prop:key}.
\end{lemma}
\begin{proof}
Without loss of generality, we assume that $W^{(0)} \neq 0$, since otherwise $(0, \Vert W^{(0)} \Vert_2) = \emptyset$. Note that according to \Cref{lem:scalarproduct_alternative_form} we can write
\begin{equation*}
\mathcal{L} = \left\{\tau_{(x,1)^T, v}: \ x \in \RR^d, v \in \B_d(0,1) \right\}.
\end{equation*}
We can even weaken this identity and infer
\begin{equation*}
\mathcal{L} = \left\{\tau_{(x,1)^T, v}: \ x \in \ker(W^{(0)})^{\perp}, v \in \B_d(0,1) \cap \ker(W^{(0)})^{\perp} \right\}.
\end{equation*}
Here, $\ker(W^{(0)})^{\perp}$ denotes the orthogonal complement of $\ker(W^{(0)})$. We further note 
\begin{equation*}
\dim(\ker(W^{(0)})^\perp) = k.
\end{equation*}

Let $\eps \in (0, \Vert W^{(0)} \Vert_2)$. From \Cref{prop:covering_ball} we infer the existence of a natural number $M \in \NN$ with $M \leq \left( \frac{8 \Vert W^{(0)} \Vert_2}{\varepsilon} + 1\right)^k$ and $v_1, ..., v_M \in \B_d(0,1) \cap \ker(W^{(0)})^\perp$ such that
\begin{equation*}
\B_d(0,1) \cap \ker(W^{(0)})^\perp \subseteq \bigcup_{i=1}^M \overline{B}_d\left(v_i,\frac{\varepsilon}{ 4 \Vert W^{(0)} \Vert_2}\right) \cap \ker(W^{(0)})^\perp.
\end{equation*}
For $i \in \{1,...,M\}$ let $w_i \defeq W^{(0)}v_i$. Fix $i \in \{1,...,M\}$ and first assume $w_i \neq 0$. Define a probability measure $\mu_i$ on $\ker(W^{(0)})^{\perp} \times \RR$ by
\begin{equation*}
\mu_i \defeq \frac{1}{\Vert w_i \Vert_2^2} \cdot \sum_{\ell = 1}^N (w_i)_\ell^2 \cdot \delta_{\left(W^{(0)}_{\ell,-}, b^{(0)}_\ell\right)^T}.
\end{equation*}
Here, we note that by definition it holds $\left(W^{(0)}_{\ell,-}\right)^T \in \ker(W^{(0)})^\perp$ for every $\ell \in \{1,...,N\}$.

Let $\mathcal{F} \defeq \left\{ \fres{f_\alpha}{\ker(W^{(0)})^\perp \times \RR} : \ \alpha \in \ker(W^{(0)})^\perp \times \RR\right\}$, where $f_\alpha$ is as introduced in the previous \Cref{lem:scalarproduct_alternative_form}. From \Cref{prop:vc_half_spaces_2} we infer that 
\begin{equation*}
\vc(\mathcal{F})  = k+1. 
\end{equation*}
Further, \Cref{prop:covering_vc} shows for every $\delta \in (0,1)$ that
\begin{equation*}
\mathcal{N}(\mathcal{F}, L^2(\mu_i), \delta) \leq \left( \frac{2}{\delta}\right)^{C'(k+1)}
\end{equation*}
with an absolute constant $C'>0$. Thus, there exists $K_i \in \NN$ with $K_i \leq \left(\frac{8 \Vert W^{(0)} \Vert_2}{\varepsilon}\right)^{C'(k+1)}$ and vectors $\alpha_1^{(i)},..., \alpha_{K_i}^{(i)} \in \ker(W^{(0)})^\perp \times \RR$ such that
\begin{equation*}
\mathcal{F} \subseteq \bigcup_{j=1}^{K_i} \overline{B}_\mathcal{F}^{L^2(\mu_i)} \left(\fres{f_{\alpha_j^{(i)}}}{\ker(W^{(0)})^\perp \times \RR},\frac{\epsilon}{4\Vert W^{(0)} \Vert_2}\right).
\end{equation*}
If $w_i=0$ let $\alpha_j^{(i)} \defeq 0 \in \ker(W^{(0)})^\perp \times \RR$ for $1\leq j \leq K_i \defeq 1$. 

Now, let $v \in \B_d(0,1) \cap \ker(W^{(0)})^\perp$ and $x \in \ker(W^{(0)})^\perp$ be arbitrary. Then there exists $i \in \{1,...,M\}$ such that 
\begin{equation} \label{eq:v_bound}
\Vert v - v_i \Vert_2 \leq \frac{\varepsilon}{4\Vert W^{(0)} \Vert_2}.
\end{equation} 
Let us first consider the case $w_i = W^{(0)}v_i \neq 0$. Then there exists $j \in \{1,..., K_i\}$ such that
\begin{equation*}
\left\Vert \fres{f_{(x,1)^T}}{\ker(W^{(0)})^\perp \times \RR} - \fres{f_{\alpha_j^{(i)}}}{\ker(W^{(0)})^\perp \times \RR}\right\Vert_{L^2(\mu_i)} \leq \frac{\epsilon}{4\Vert W^{(0)} \Vert_2}.
\end{equation*} 
We compute
\begin{align}
\left\Vert \tau_{(x,1)^T,v}- \tau_{\alpha_j^{(i)}, v_i}\right\Vert_2 &\leq \left\Vert \tau_{(x,1)^T,v} - \tau_{(x,1)^T, v_i}\right\Vert_2 + \left\Vert \tau_{(x,1)^T, v_i} - \tau_{\alpha_j^{(i)},v_i}\right\Vert_2 \nonumber\\
&= \left\Vert \tau_{(x,1)^T, v- v_i}\right\Vert_2 + \left\Vert \tau_{(x,1)^T, v_i} - \tau_{\alpha_j^{(i)},v_i}\right\Vert_2 \nonumber\\
\overset{\text{Lemma}~\ref{lem:scalarproduct_alternative_form}~\eqref{item:lem_2}}&{\leq} \Vert W^{(0)} \Vert_2 \cdot \Vert v - v_i \Vert_2 + \left\Vert \tau_{(x,1)^T, v_i} - \tau_{\alpha_j^{(i)},v_i}\right\Vert_2 \nonumber\\
\label{eq:first_bound}
\overset{\eqref{eq:v_bound}}&{\leq} \frac{\varepsilon}{4} + \left\Vert \tau_{(x,1)^T, v_i} - \tau_{\alpha_j^{(i)},v_i}\right\Vert_2.
\end{align}
Finally, we note because of $w_i = W^{(0)}v_i$ and by definition of $\mu_i$ that
\begin{align}
\left\Vert \tau_{(x,1)^T, v_i} - \tau_{\alpha_j^{(i)}, v_i}\right\Vert_2^2 &= \sum_{\ell = 1}^N (W^{(0)}v_i)_\ell^2 \cdot \left( f_{(x,1)^T}\left((W^{(0)}_{\ell, -}, b^{(0)}_\ell)^T\right) - f_{\alpha_j^{(i)}}\left((W^{(0)}_{\ell, -}, b^{(0)}_\ell)^T\right)\right)^2 \nonumber\\
&= \Vert w_i \Vert_2^2 \cdot \left\Vert \fres{f_{(x,1)^T}}{\ker(W^{(0)})^\perp \times \RR} - \fres{f_{\alpha_j^{(i)}}}{\ker(W^{(0)})^\perp \times \RR}\right\Vert^2_{L^2(\mu_i)} \nonumber \\
&\leq \Vert w_i \Vert_2^2 \cdot \left(\frac{\eps}{4\Vert W^{(0)} \Vert_2}\right)^2 
\label{eq:second_bound}\leq \Vert W^{(0)} \Vert_2^2 \cdot \Vert v_i \Vert_2^2 \cdot \left(\frac{\eps}{4\Vert W^{(0)} \Vert_2}\right)^2 \leq \left(\frac{\eps}{4}\right)^2,
\end{align}
and this trivially remains true in the case $w_i = 0$ if we choose $j=1$.

Overall, \eqref{eq:first_bound} and \eqref{eq:second_bound} together imply in any case that
\begin{equation*}
\left\Vert \tau_{(x,1)^T, v} - \tau_{\alpha_j^{(i)},v_i} \right\Vert_2 \leq \frac{\eps}{2}.
\end{equation*}
Hence, the set 
\begin{equation*}
\left\{ \tau_{\alpha_j^{(i)}, v_i}: \ 1 \leq i \leq M, \ 1 \leq j \leq K_i\right\}
\end{equation*}
is an $\frac{\eps}{2}$-net of $\mathcal{L}$ with respect to $\Vert \cdot \Vert_2$. However, this set does not necessarily have to be a subset of $\mathcal{L}$. Yet, using \cite[Exercise 4.2.9]{vershynin_high-dimensional_2018} for the first inequality, we get
\begin{align*}
\mathcal{N}(\mathcal{L}, \Vert \cdot \Vert_2, \eps) &\leq \sum_{i=1}^M K_i \leq \left(\frac{8 \Vert W^{(0)} \Vert_2}{\eps} + 1\right)^k \cdot \left(\frac{8\Vert W^{(0)} \Vert_2}{\eps}\right)^{C'(k+1)} \\
\overset{\eps < \Vert W^{(0)} \Vert_2}&{\leq} \left(\frac{9\Vert W^{(0)} \Vert_2}{\eps}\right)^{C'(k+1) + k} 
\leq \left( \frac{9\Vert W^{(0)} \Vert_2}{\eps}\right)^{(2C'+1)k},
\end{align*}
so the claim follows choosing $C= 2C' + 1$.
\end{proof}

The derived bound for the covering number of $\mathcal{L}$ leads to the following bound when we only assume randomness in $W^{(1)}$. 
\begin{proposition}\label{thm:lower_bound_1}
There exists an absolute constant $C>0$ such that for fixed $W^{(0)} \in \RR^{N \times d}$ and $b^{(0)} \in \RR^N$, writing $k = \rang(W^{(0)})$, the following hold:
\begin{enumerate}
\item{
For any $u \geq 0$, we have
\begin{equation*}
\underset{x \in \RR^d}{\sup} \left\Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\right\Vert_2 \leq C \cdot \Vert W^{(0)} \Vert_2 \cdot (\sqrt{k} + u)
\end{equation*}
with probability at least $1 - 2\exp(-u^2)$ (with respect to the choice of $W^{(1)}$).}
\item{$\displaystyle
\underset{W^{(1)}}{\EE} \left[ \underset{x \in \RR^d}{\sup} \left\Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\right\Vert_2\right] \leq C \cdot \sqrt{k} \cdot \Vert W^{(0)} \Vert_2.$
}
\end{enumerate}
\end{proposition}
\begin{proof}
Without loss of generality we assume $k \geq 1$. We observe
\begin{align*}
 \int_0^{\Vert W^{(0)}\Vert_2} \sqrt{\ln (\mathcal{N}(\mathcal{L}, \Vert \cdot \Vert_2, \eps))} \ \dd\eps \overset{\text{Lemma}~\ref{lem:cov_num_bound}}&{\leq}  \int_0^{\Vert W^{(0)} \Vert_2}\sqrt{C_1 \cdot k} \cdot \sqrt{\ln \left( \frac{9 \Vert W^{(0)} \Vert_2}{\eps}\right)} \ \dd\eps \\
&= \sqrt{C_1} \cdot \sqrt{k} \cdot 9 \Vert W^{(0)} \Vert_2 \cdot \int_0^{\frac{1}{9}} \sqrt{\ln (1/\sigma)} \ \dd\sigma \\
& \leq C_2 \cdot \sqrt{k} \cdot \Vert W^{(0)} \Vert_2.
\end{align*}
Here, $C_1>0$ is the absolute constant from \Cref{lem:cov_num_bound} and $C_2 \defeq 9\cdot\sqrt{C_1} \cdot \int_0^{1/9} \sqrt{\ln (1/\sigma)} \ \dd \sigma$. At the equality, we applied the substitution $\frac{1}{\sigma} = \frac{9 \Vert W^{(0)} \Vert_2}{\eps}$. We combine this estimate with \Cref{prop:key} and get for any $u \geq 0$ that
\begin{align*}
\underset{x \in \RR^d}{\sup} \left\Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\right\Vert_2 &\leq C_3 \cdot \left(C_2 \cdot \sqrt{k} \cdot \Vert W^{(0)} \Vert_2 + u \cdot \Vert W^{(0)} \Vert_2 \right) \\
&\leq C_3 \cdot \max\{1, C_2\} \cdot \Vert W^{(0)} \Vert_2 \cdot (\sqrt{k} + u)
\end{align*}
with probability at least $1 - 2\exp(-u^2)$, as well as
\begin{equation*}
\underset{W^{(1)}}{\EE} \left[ \underset{x \in \RR^d}{\sup} \Vert W^{(1)}D^{(0)}(x) W^{(0)} \Vert_2\right] \leq C_3 \cdot C_2 \cdot \sqrt{k} \cdot \Vert W^{(0)} \Vert_2,
\end{equation*}
where $C_3 > 0$ is the absolute constant from \Cref{prop:key}. Hence, the claim follows by letting $C \defeq C_3\max\{C_2,1\}$.
\end{proof}
Until now, we have conditioned on $W^{(0)}, b^{(0)}$. Reintroducing the randomness with respect to $W^{(0)}, b^{(0)}$ leads to the following statement.
\begin{proposition} \label{thm:pre_main}
There exist absolute constants $C, c_1 > 0$ such that, writing $k \defeq \min\{d,N\}$, the following hold:
\begin{enumerate}
\item{ \label{item1:pre_main}
For any $u,t \geq 0$ it holds
\begin{equation*}
\underset{x \in \RR^d}{\sup} \Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\Vert_2 \leq C\cdot \left(1 + \frac{\sqrt{d} + t}{\sqrt{N}}\right)(\sqrt{k} + u)
\end{equation*}
with probability at least $(1-2\exp(-u^2))_+ \cdot (1-2\exp(-c_1t^2))_+$ with respect to the choice of $W^{(0)}, W^{(1)}, b^{(0)}, b^{(1)}$.
}
\item{ \label{item2:pre_main}
$ \displaystyle
\EE \left[ \underset{x \in \RR^d}{\sup} \left\Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\right\Vert_2\right] \leq C \cdot \left(1+ \frac{\sqrt{d} }{\sqrt{N}} \right) \cdot \sqrt{k}.
$
}
\end{enumerate}
\end{proposition}
\begin{proof}
We first note that for any matrix $W^{(0)}$ it holds $\rang(W^{(0)}) \leq k$. 

Let us first deal with Part \eqref{item1:pre_main}. Let $C_2 > 0$ be the (absolute) constant from \Cref{thm:lower_bound_1} and $C \defeq \sqrt{2}C_2$. For fixed $u,t \geq 0$ let 
\begin{equation*}
A \defeq \left\{ (W^{(1)}, W^{(0)}, b^{(0)}): \ \underset{x \in \RR^d}{\sup} \Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\Vert_2 \leq C \left(1 + \frac{\sqrt{d} + t}{\sqrt{N}}\right)(\sqrt{k} + u)\right\}.
\end{equation*}
Furthermore let 
\begin{equation*}
A_1 \defeq \left\{ (W^{(0)}, b^{(0)}) : \ \Vert W^{(0)} \Vert_2 \leq \sqrt{2} \left(1 + \frac{\sqrt{d} + t}{\sqrt{N}}\right)\right\}
\end{equation*}
and for fixed $(W^{(0)}, b^{(0)})$, let
\begin{equation*}
A_2\left(W^{(0)}, b^{(0)}\right) \defeq  \left\{ W^{(1)}: \ \underset{x \in \RR^d}{\sup} \Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\Vert_2 \leq C_2 \cdot \Vert W^{(0)}  \Vert_2 \cdot (\sqrt{k} + u)\right\}.
\end{equation*}
Note that then
\begin{equation*}
(W^{(0)}, b^{(0)}) \in A_1, \ W^{(1)} \in A_2\left(W^{(0)}, b^{(0)}\right) \quad \Longrightarrow \quad  (W^{(1)}, W^{(0)}, b^{(0)}) \in A.
\end{equation*}
From \Cref{thm:lower_bound_1} and since probabilities are always non-negative we infer
\begin{equation*}
\PP^{W^{(1)}} \left(A_2\left(W^{(0)}, b^{(0)}\right)\right) \geq (1 - 2\exp(-u^2))_+
\end{equation*}
for any $(W^{(0)}, b^{(0)})$. Furthermore, it holds 
\begin{equation*}
\Vert W^{(0)} \Vert_2 = \sqrt{\frac{2}{N}} \cdot \left\Vert \sqrt{\frac{N}{2}} \cdot W^{(0)} \right\Vert_2 \leq \sqrt{\frac{2}{N}}\cdot (\sqrt{N} + \sqrt{d} + t) = \sqrt{2}\left(1 + \frac{\sqrt{d} + t}{\sqrt{N}}\right)
\end{equation*}
with probability at least $(1 - 2 \exp(-c_1 t^2))_+$ for some absolute constant $c_1 > 0$, as follows from \cite[Corollary 7.3.3]{vershynin_high-dimensional_2018} by noting that the matrix $\sqrt{\frac{N}{2}} W^{(0)}$ has independent $\mathcal{N}(0,1)$-entries. The claim of Part \eqref{item1:pre_main} then follows from \Cref{prop:highprob}.

Let us now deal with Part \eqref{item2:pre_main}. Using \Cref{thm:lower_bound_1} we derive
\begin{equation*}
\underset{W^{(0)},b^{(0)},W^{(1)}}{\EE} \left[ \underset{x \in \RR^d}{\sup} \left\Vert W^{(1)} \cdot D^{(0)}(x) \cdot W^{(0)}\right\Vert_2 \right]\leq C_2 \cdot \sqrt{k} \cdot \underset{W^{(0)}}{\EE} \ \Vert W^{(0)} \Vert_2.
\end{equation*}
From \cite[Theorem 7.3.1]{vershynin_high-dimensional_2018} we get
\begin{equation*}
\underset{W^{(0)}}{\EE} \ \Vert W^{(0)} \Vert_2 = \sqrt{\frac{2}{N}} \cdot \underset{W^{(0)}}{\EE} \   \left\Vert \sqrt{\frac{N}{2}} \cdot W^{(0)} \right\Vert_2 \leq\sqrt{\frac{2}{N}}(\sqrt{N} + \sqrt{d}) =\sqrt{2} \left(1 + \sqrt{\frac{d}{N}}\right).
\end{equation*}
This yields the claim.
\end{proof}

The transfer of \Cref{thm:pre_main} to obtain an upper bound of the Lipschitz constant of shallow ReLU networks follows directly from \eqref{eq:lowbound}.
\begin{theorem} \label{thm:1_main}
There exist absolute constants $C, c_1 > 0$ such that if $\Phi: \RR^d \to \RR$ is a random shallow ReLU network with width $N$ satisfying \Cref{assum:1} and writing $k \defeq \min\{d,N\}$, the following hold:
\begin{enumerate}
\item{For any $u,t \geq 0$, we have
\begin{equation*}
\lip(\Phi) \leq C \cdot \left(1 + \frac{\sqrt{d} + t}{\sqrt{N}}\right)(\sqrt{k} + u)
\end{equation*}
with probability at least $(1-2\exp(-u^2))_+ \cdot (1-2\exp(-c_1t^2))_+$.}
\item{$ \displaystyle
\EE \left[\lip(\Phi) \right]  \leq C \cdot \left(1+ \frac{\sqrt{d} }{\sqrt{N}} \right) \cdot \sqrt{k}.
$}
\end{enumerate}
\end{theorem}


By plugging in certain values for $u$ and $t$, we can now prove \Cref{thm:main_1}.
\renewcommand*{\proofname}{Proof of \Cref{thm:main_1}}
\begin{proof}
Let $\widetilde{C}$ and $\widetilde{c_1}$ be the relabeled constants from \Cref{thm:1_main} and $k \defeq \min\{d,N\}$, as well as $\ell \defeq \max\{d,N\}$. To show Part (1), we set $u = \sqrt{k}$ and $t = \sqrt{\ell}$. Then, since the inequality $\sqrt{\ln(2)} < \sqrt{\ln(\ee)} = 1$ holds, we get $u \geq \sqrt{\ln(2)}$ and thus $1-2\exp(-u^2) \geq 0$. \Cref{thm:1_main} shows 
\begin{equation*}
\lip(\Phi) \leq 2\widetilde{C} \cdot \left(1 + \frac{\sqrt{d} +\sqrt{\ell}}{\sqrt{N}}\right) \sqrt{k} 
\end{equation*}
with probability at least $(1-2\exp(-k)) \cdot (1-2\exp(-\widetilde{c_1} \ell))_+$. If $d \leq N$ we get
\begin{equation*}
2\widetilde{C}\cdot \left(1 + \frac{\sqrt{d} +\sqrt{\ell}}{\sqrt{N}}\right) \sqrt{k} \leq 2\widetilde{C}\cdot  \left(1 + \frac{\sqrt{N} + \sqrt{N}}{\sqrt{N}}\right) \cdot \sqrt{d} = 6\widetilde{C} \cdot \sqrt{d}
\end{equation*}
and if $d \geq N$ we infer
\begin{align*}
2\widetilde{C}\cdot \left(1 + \frac{\sqrt{d} +\sqrt{\ell}}{\sqrt{N}}\right) \sqrt{k} = 2\widetilde{C}\cdot \left(1 + \frac{\sqrt{d} +\sqrt{d}}{\sqrt{N}}\right) \sqrt{N}= 2\widetilde{C}\cdot \left(\sqrt{N} + \sqrt{d} + \sqrt{d}\right) \leq 6\widetilde{C} \cdot \sqrt{d}.
\end{align*}
For Part (2) note that, if $d \leq N$ is satisfied, \Cref{thm:1_main} gives us
\begin{equation*}
\EE \left[\lip(\Phi) \right]  \leq \widetilde{C}\cdot \left(1+ \frac{\sqrt{d} }{\sqrt{N}} \right) \cdot \sqrt{d} \leq 2 \widetilde{C} \cdot \sqrt{d}
\end{equation*}
and if $d \geq N$ we get
\begin{equation*}
\EE \left[\lip(\Phi) \right]  \leq \widetilde{C} \cdot\left(1+ \frac{\sqrt{d} }{\sqrt{N}} \right) \cdot \sqrt{N} = \widetilde{C}\cdot \left(\sqrt{N} + \sqrt{d}\right) \leq 2 \widetilde{C}\cdot \sqrt{d}.
\end{equation*}
Overall, the claim is satisfied with $C \defeq  6\widetilde{C}$ and $c_1 \defeq \widetilde{c_1}$.
\end{proof}
\renewcommand*{\proofname}{Proof}

