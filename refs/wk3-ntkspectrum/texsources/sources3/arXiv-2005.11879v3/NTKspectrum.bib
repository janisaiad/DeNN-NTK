@phdthesis{neal1995bayesian,
	title={Bayesian learning for neural networks},
	author={Neal, Radford M},
	year={1995},
	school={University of Toronto}
}

@inproceedings{poole2016exponential,
	title={Exponential expressivity in deep neural networks through transient chaos},
	author={Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
	booktitle={Advances in Neural Information Processing Systems},
	pages={3360--3368},
	year={2016}
}

@inproceedings{lee2018deep,
	title={Deep neural networks as {G}aussian processes},
	author={Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{daniely2016toward,
	title={Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity},
	author={Daniely, Amit and Frostig, Roy and Singer, Yoram},
	booktitle={Advances In Neural Information Processing Systems},
	pages={2253--2261},
	year={2016}
}

@inproceedings{williams1997computing,
	title={Computing with infinite networks},
	author={Williams, Christopher KI},
	booktitle={Advances in Neural Information Processing Systems},
	pages={295--301},
	year={1997}
}

@inproceedings{schoenholz2017deep,
	title={Deep information propagation},
	author={Schoenholz, Samuel S and Gilmer, Justin and Ganguli, Surya and Sohl-Dickstein, Jascha},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{rahimi2008random,
	title={Random features for large-scale kernel machines},
	author={Rahimi, Ali and Recht, Benjamin},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1177--1184},
	year={2008}
}

@inproceedings{allen2019convergence,
	title={A Convergence Theory for Deep Learning via Over-Parameterization},
	author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	booktitle={International Conference on Machine Learning},
	pages={242--252},
	year={2019}
}

@inproceedings{du2019gradienta,
	title={Gradient descent provably optimizes over-parameterized neural networks},
	author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{du2019gradientb,
	title={Gradient descent finds global minima of deep neural networks},
	author={Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	booktitle={International Conference on Machine Learning},
	year={2019}
}

@inproceedings{jacot2018neural,
	title={Neural tangent kernel: {C}onvergence and generalization in neural networks},
	author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	booktitle={Advances in Neural Information Processing Systems},
	pages={8571--8580},
	year={2018}
}

@inproceedings{cho2009kernel,
	title={Kernel methods for deep learning},
	author={Cho, Youngmin and Saul, Lawrence K},
	booktitle={Advances in Neural Information Processing Systems},
	pages={342--350},
	year={2009}
}

@article{advani2017high,
	title={High-dimensional dynamics of generalization error in neural networks},
	author={Advani, Madhu S and Saxe, Andrew M},
	journal={arXiv preprint arXiv:1710.03667},
	year={2017}
}

@article{xiao2019disentangling,
	title={Disentangling trainability and generalization in deep learning},
	author={Xiao, Lechao and Pennington, Jeffrey and Schoenholz, Samuel S},
	journal={arXiv preprint arXiv:1912.13053},
	year={2019}
}

@article{yang2019fine,
	title={A fine-grained spectral perspective on neural networks},
	author={Yang, Greg and Salman, Hadi},
	journal={arXiv preprint arXiv:1907.10599},
	year={2019}
}

@inproceedings{lee2019wide,
	title={Wide neural networks of any depth evolve as linear models under gradient descent},
	author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
	booktitle={Advances in Neural Information Processing Systems},
	pages={8570--8581},
	year={2019}
}

@article{yang2019scaling,
	title={Scaling limits of wide neural networks with weight sharing: {G}aussian process behavior, gradient independence, and neural tangent kernel derivation},
	author={Yang, Greg},
	journal={arXiv preprint arXiv:1902.04760},
	year={2019}
}

@inproceedings{chizat2019lazy,
	title={On lazy training in differentiable programming},
	author={Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2933--2943},
	year={2019}
}

@inproceedings{pennington2017nonlinear,
	title={Nonlinear random matrix theory for deep learning},
	author={Pennington, Jeffrey and Worah, Pratik},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2637--2646},
	year={2017}
}

@article{benigni2019eigenvalue,
	title={Eigenvalue distribution of nonlinear models of random matrices},
	author={Benigni, Lucas and P{\'e}ch{\'e}, Sandrine},
	journal={arXiv preprint arXiv:1904.03090},
	year={2019}
}

@article{louart2018random,
	title={A random matrix approach to neural networks},
	author={Louart, Cosme and Liao, Zhenyu and Couillet, Romain},
	journal={The Annals of Applied Probability},
	volume={28},
	number={2},
	pages={1190--1248},
	year={2018},
	publisher={Institute of Mathematical Statistics}
}

@article{dicker2016ridge,
	title={Ridge regression and asymptotic minimax estimation over spheres of growing dimension},
	author={Dicker, Lee H},
	journal={Bernoulli},
	volume={22},
	number={1},
	pages={1--37},
	year={2016},
	publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{hastie2019surprises,
	title={Surprises in high-dimensional ridgeless least squares interpolation},
	author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
	journal={arXiv preprint arXiv:1903.08560},
	year={2019}
}

@article{dobriban2018high,
	title={High-dimensional asymptotics of prediction: Ridge regression and classification},
	author={Dobriban, Edgar and Wager, Stefan},
	journal={The Annals of Statistics},
	volume={46},
	number={1},
	pages={247--279},
	year={2018},
	publisher={Institute of Mathematical Statistics}
}

@article{mei2019generalization,
	title={The generalization error of random features regression: Precise asymptotics and double descent curve},
	author={Mei, Song and Montanari, Andrea},
	journal={arXiv preprint arXiv:1908.05355},
	year={2019}
}

@inproceedings{liao2018spectrum,
	title={On the Spectrum of Random Features Maps of High Dimensional Data},
	author={Liao, Zhenyu and Couillet, Romain},
	booktitle={International Conference on Machine Learning},
	pages={3063--3071},
	year={2018}
}

@inproceedings{pennington2017geometry,
	title={Geometry of neural network loss surfaces via random matrix theory},
	author={Pennington, Jeffrey and Bahri, Yasaman},
	booktitle={International Conference on Machine Learning},
	pages={2798--2806},
	year={2017},
}

@inproceedings{pennington2018spectrum,
	title={The spectrum of the {F}isher information matrix of a single-hidden-layer neural network},
	author={Pennington, Jeffrey and Worah, Pratik},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5410--5419},
	year={2018}
}

@inproceedings{arora2019exact,
	title={On exact computation with an infinitely wide neural net},
	author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	booktitle={Advances in Neural Information Processing Systems},
	pages={8139--8148},
	year={2019}
}

@article{jacot2019asymptotic,
	title={The asymptotic spectrum of the Hessian of DNN throughout training},
	author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	journal={arXiv preprint arXiv:1910.02875},
	year={2019}
}

@inproceedings{karakida2019universal,
	title={Universal Statistics of {F}isher Information in Deep Neural Networks: {M}ean Field Approach},
	author={Karakida, Ryo and Akaho, Shotaro and Amari, Shun-ichi},
	booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
	pages={1032--1041},
	year={2019}
}

@article{geiger2019jamming,
	title={Jamming transition as a paradigm to understand the loss landscape of deep neural networks},
	author={Geiger, Mario and Spigler, Stefano and d'Ascoli, St{\'e}phane and Sagun, Levent and Baity-Jesi, Marco and Biroli, Giulio and Wyart, Matthieu},
	journal={Physical Review E},
	volume={100},
	number={1},
	pages={012115},
	year={2019},
	publisher={APS}
}

@inproceedings{sagun2018empirical,
	title={Empirical analysis of the hessian of over-parametrized neural networks},
	author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@article{el2010spectrum,
	title={The spectrum of kernel random matrices},
	author={El Karoui, Noureddine},
	journal={The Annals of Statistics},
	volume={38},
	number={1},
	pages={1--50},
	year={2010},
	publisher={Institute of Mathematical Statistics}
}

@article{couillet2016kernel,
	title={Kernel spectral clustering of large dimensional data},
	author={Couillet, Romain and Benaych-Georges, Florent},
	journal={Electronic Journal of Statistics},
	volume={10},
	number={1},
	pages={1393--1454},
	year={2016},
	publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{cheng2013spectrum,
	title={The spectrum of random inner-product kernel matrices},
	author={Cheng, Xiuyuan and Singer, Amit},
	journal={Random Matrices: Theory and Applications},
	volume={2},
	number={04},
	pages={1350010},
	year={2013},
	publisher={World Scientific}
}

@article{do2013spectrum,
	title={The spectrum of random kernel matrices: {U}niversality results for rough and varying kernels},
	author={Do, Yen and Vu, Van},
	journal={Random Matrices: Theory and Applications},
	volume={2},
	number={03},
	pages={1350005},
	year={2013},
	publisher={World Scientific}
}

@article{fan2019spectral,
	title={The spectral norm of random inner-product kernel matrices},
	author={Fan, Zhou and Montanari, Andrea},
	journal={Probability Theory and Related Fields},
	volume={173},
	number={1-2},
	pages={27--85},
	year={2019},
	publisher={Springer}
}

@inproceedings{yehudai2019power,
	title={On the power and limitations of random features for understanding neural networks},
	author={Yehudai, Gilad and Shamir, Ohad},
	booktitle={Advances in Neural Information Processing Systems},
	pages={6594--6604},
	year={2019}
}

@inproceedings{ghorbani2019limitations,
	title={Limitations of Lazy Training of Two-layers Neural Network},
	author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
	booktitle={Advances in Neural Information Processing Systems},
	pages={9108--9118},
	year={2019}
}

@article{ghorbani2019linearized,
	title={Linearized two-layers neural networks in high dimension},
	author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
	journal={arXiv preprint arXiv:1904.12191},
	year={2019}
}

@article{liang2019risk,
	title={On the risk of minimum-norm interpolants and restricted lower isometry of kernels},
	author={Liang, Tengyuan and Rakhlin, Alexander and Zhai, Xiyu},
	journal={arXiv preprint arXiv:1908.10292},
	year={2019}
}

@article{huang2019dynamics,
	title={Dynamics of deep neural networks and neural tangent hierarchy},
	author={Huang, Jiaoyang and Yau, Horng-Tzer},
	journal={arXiv preprint arXiv:1909.08156},
	year={2019}
}

@article{dyer2019asymptotics,
	title={Asymptotics of wide networks from {F}eynman diagrams},
	author={Dyer, Ethan and Gur-Ari, Guy},
	journal={arXiv preprint arXiv:1909.11304},
	year={2019}
}

@book{anderson2010introduction,
	title={An Introduction to Random Matrices},
	author={Anderson, Greg W and Guionnet, Alice and Zeitouni, Ofer},
	year={2010},
	publisher={Cambridge University Press}
}

@article{marchenko1967distribution,
	title={Distribution of eigenvalues for some sets of random matrices},
	author={Marchenko, Vladimir Alexandrovich and Pastur, Leonid Andreevich},
	journal={Matematicheskii Sbornik},
	volume={114},
	number={4},
	pages={507--536},
	year={1967},
}

@inproceedings{ioffe2015batch,
	title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	booktitle={International Conference on Machine Learning},
	pages={448--456},
	year={2015}
}

@article{haagerup2005new,
	title={A new application of random matrices: $\operatorname{Ext}(C^*_{\text{red}}(F_2))$ is not a group},
	author={Haagerup, Uffe and Thorbj{\o}rnsen, Steen},
	journal={Annals of Mathematics},
	pages={711--775},
	year={2005},
	publisher={JSTOR}
}

@book{bai2010spectral,
	title={Spectral analysis of large dimensional random matrices},
	author={Bai, Zhidong and Silverstein, Jack W},
	volume={20},
	year={2010},
	publisher={Springer}
}

@book{tao2012topics,
	title={Topics in Random Matrix Theory},
	author={Tao, Terence},
	isbn={9780821874301},
	lccn={2011045194},
	series={Graduate studies in mathematics},
	year={2012},
	publisher={American Mathematical Society}
}

@book{vershynin2018high,
	title={High-Dimensional Probability: An Introduction with Applications in Data Science},
	author={Vershynin, R.},
	isbn={9781108415194},
	lccn={2018016910},
	series={Cambridge Series in Statistical and Probabilistic Mathematics},
	url={https://urldefense.com/v3/__https://books.google.com/books?id=NDdqDwAAQBAJ__;!!Mih3wA!TFBDRN8zS8fVXt0SS3Z2GWpWAG9CSeMdOtubQRGZN_GclCfwqDVjPolz_ScogDD-kw$ },
	year={2018},
	publisher={Cambridge University Press}
}

@article{rudelson2013hanson,
	title={Hanson-{W}right inequality and sub-gaussian concentration},
	author={Rudelson, Mark and Vershynin, Roman},
	journal={Electronic Communications in Probability},
	volume={18},
	year={2013},
	publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{vershynin2010introduction,
	title={Introduction to the non-asymptotic analysis of random matrices},
	author={Vershynin, Roman},
	journal={arXiv preprint arXiv:1011.3027},
	year={2010}
}

@article{adamczak2015concentration,
	title={Concentration inequalities for non-{L}ipschitz functions with bounded derivatives of higher order},
	author={Adamczak, Rados{\l}aw and Wolff, Pawe{\l}},
	journal={Probability Theory and Related Fields},
	volume={162},
	number={3-4},
	pages={531--586},
	year={2015},
	publisher={Springer}
}

@article{adamczak2015note,
	title={A note on the {H}anson-{W}right inequality for random vectors with dependencies},
	author={Adamczak, Radoslaw},
	journal={Electronic Communications in Probability},
	volume={20},
	year={2015},
	publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{vu2015random,
	title={Random weighted projections, random quadratic forms and random eigenvectors},
	author={Vu, Van and Wang, Ke},
	journal={Random Structures \& Algorithms},
	volume={47},
	number={4},
	pages={792--821},
	year={2015},
	publisher={Wiley Online Library}
}

@article{kasiviswanathan2019restricted,
	title={Restricted isometry property under high correlations},
	author={Kasiviswanathan, Shiva Prasad and Rudelson, Mark},
	journal={arXiv preprint arXiv:1904.05510},
	year={2019}
}

@book{boucheron2013concentration,
	title={Concentration Inequalities: A Nonasymptotic Theory of Independence},
	author={Boucheron, S. and Lugosi, G. and Massart, P.},
	isbn={9780199535255},
	lccn={2012277339},
	url={https://urldefense.com/v3/__https://books.google.com/books?id=5oo4YIz6tR0C__;!!Mih3wA!TFBDRN8zS8fVXt0SS3Z2GWpWAG9CSeMdOtubQRGZN_GclCfwqDVjPolz_SdbrpwjKA$ },
	year={2013},
	publisher={OUP Oxford}
}

@book{johnson1990matrix,
	title={Matrix Theory and Applications},
	author={Johnson, C.R.},
	isbn={9780821801543},
	lccn={lc90030584},
	series={AMS Short Course Lecture Notes},
	url={https://urldefense.com/v3/__https://books.google.com/books?id=KHrHCQAAQBAJ__;!!Mih3wA!TFBDRN8zS8fVXt0SS3Z2GWpWAG9CSeMdOtubQRGZN_GclCfwqDVjPolz_Sc7yi31BQ$ },
	year={1990},
	publisher={American Mathematical Society}
}

@article{adlam2019random,
	title={A Random Matrix Perspective on Mixtures of Nonlinearities for Deep Learning},
	author={Adlam, Ben and Levinson, Jake and Pennington, Jeffrey},
	journal={arXiv preprint arXiv:1912.00827},
	year={2019}
}

@article{krizhevsky2009learning,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, Alex},
	year={2009},
	publisher={Citeseer}
} 

@article{benaych2010surprising,
	title={On a surprising relation between the Marchenko-Pastur law, rectangular and square free convolutions},
	author={Benaych-Georges, Florent},
	journal={Annales de l'IHP Probabilit{\'e}s et statistiques},
	volume={46},
	number={3},
	pages={644--652},
	year={2010}
}

@inproceedings{adlam2020neural,
	title={The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization},
	author={Adlam, Ben and Pennington, Jeffrey},
	booktitle={International Conference on Machine Learning},
	year={2020}
}

@article{peche2019note,
	title={A note on the Pennington-Worah distribution},
	author={P{\'e}ch{\'e}, S},
	journal={Electronic Communications in Probability},
	volume={24},
	year={2019},
	publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@inproceedings{dascoli2020double,
	title={Double trouble in double descent: {B}ias and variance(s) in the lazy regime},
	author={d'Ascoli, St{\'e}phane and Refinetti, Maria and Biroli, Giulio and Krzakala, Florent},
	booktitle={International Conference on Machine Learning},
	year={2020}
}

@inproceedings{matthews2018gaussian,
	title={Gaussian Process Behaviour in Wide Deep Neural Networks},
	author={Matthews, Alexander G de G and Hron, Jiri and Rowland, Mark and Turner, Richard E and Ghahramani, Zoubin},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{liao2018dynamics, 
	title = {The Dynamics of Learning: A Random Matrix Approach}, 
	author = {Liao, Zhenyu and Couillet, Romain}, 
	booktitle = {International Conference on Machine Learning},
	year={2018}
}

@inproceedings{liao2019inner,
	title={On Inner-Product Kernels of High Dimensional Data},
	author={Liao, Zhenyu and Couillet, Romain},
	booktitle={2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)},
	pages={579--583},
	year={2019},
	organization={IEEE}
}