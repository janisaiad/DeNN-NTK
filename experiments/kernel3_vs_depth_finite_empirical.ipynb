{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6917d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from finitewidth.kernel3_empirical import Kernel3Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0273bf9e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "N = 8  # Number of data points (smaller due to computational cost)\n",
    "D_IN = 20  # Input dimension\n",
    "M = 100  # Network width\n",
    "L_VALUES = np.arange(2, 5)  # Network depths\n",
    "RANDOM_SEED = 42\n",
    "PATH_TO_PLOTS = \"/home/janis/STG3A/deeperorwider/experiments/plots\"\n",
    "PATH_TO_DATA = \"/home/janis/STG3A/deeperorwider/experiments/data\"\n",
    "\n",
    "# Ensure paths exist\n",
    "os.makedirs(PATH_TO_PLOTS, exist_ok=True)\n",
    "os.makedirs(PATH_TO_DATA, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05444131",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Activation Function ---\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return (x > 0).astype(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9e6df4b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Data and Network Initialization ---\n",
    "def generate_data(key, n_samples, n_features):\n",
    "    \"\"\"Generate random data and normalize it.\"\"\"\n",
    "    rng = jax.random.PRNGKey(key)\n",
    "    data = jax.random.normal(rng, (n_samples, n_features))\n",
    "    norm = jnp.linalg.norm(data, axis=1, keepdims=True)\n",
    "    return data / norm\n",
    "\n",
    "def init_network(key, L, d_in, m):\n",
    "    \n",
    "    \"\"\"Initialize network weights.\"\"\"\n",
    "    # the std for weights is 1/sqrt(m) by default but we want sqrt(2/m)\n",
    "    keys = jax.random.split(key, L + 1)\n",
    "    weights = []\n",
    "    weights.append(jax.random.normal(keys[0], (m, d_in)) * jnp.sqrt(2/d_in))\n",
    "    \n",
    "    for i in range(1, L):\n",
    "        weights.append(jax.random.normal(keys[i], (m, m)) * jnp.sqrt(2/m))\n",
    "    weights.append(jax.random.normal(keys[L], (m,)) * jnp.sqrt(2/m))\n",
    "    return weights\n",
    "\n",
    "def compute_features_and_derivatives(weights, data):\n",
    "    \"\"\"we perform a forward pass to get all feature maps and sigma derivatives.\"\"\"\n",
    "    H = len(weights) - 1\n",
    "    m = weights[0].shape[0]\n",
    "\n",
    "    feature_maps = {0: [x for x in data]}\n",
    "    sigma_derivatives = {}\n",
    "    current_activations = feature_maps[0]\n",
    "\n",
    "    for l in range(1, H + 1):\n",
    "        W = weights[l-1]\n",
    "        pre_activations = [W @ x for x in current_activations]\n",
    "        sigma_derivatives[l] = [jnp.diag(relu_prime(pre_act)) for pre_act in pre_activations]\n",
    "        current_activations = [(1/jnp.sqrt(m)) * relu(pre_act) for pre_act in pre_activations]\n",
    "        feature_maps[l] = current_activations\n",
    "        \n",
    "    return feature_maps, sigma_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b83f2a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the analysis of the empirical K3 tensor...\n",
      "Computing for L = 2 layers (M=100)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PRNGKey accepts a scalar seed, but was given an array of shape (2,) != (). Use jax.vmap for batching",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m data_key, net_key = jax.random.split(key)\n\u001b[32m     14\u001b[39m weights = init_network(net_key, L, D_IN, M)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m data = \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_IN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Forward pass to get necessary values\u001b[39;00m\n\u001b[32m     18\u001b[39m feature_maps, sigma_derivatives = compute_features_and_derivatives(weights, data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_data\u001b[39m\u001b[34m(key, n_samples, n_features)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_data\u001b[39m(key, n_samples, n_features):\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate random data and normalize it.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     rng = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     data = jax.random.normal(rng, (n_samples, n_features))\n\u001b[32m      6\u001b[39m     norm = jnp.linalg.norm(data, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/STG3A/deeperorwider/.venv/lib/python3.11/site-packages/jax/_src/random.py:248\u001b[39m, in \u001b[36mPRNGKey\u001b[39m\u001b[34m(seed, impl)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mPRNGKey\u001b[39m(seed: \u001b[38;5;28mint\u001b[39m | ArrayLike, *,\n\u001b[32m    223\u001b[39m             impl: PRNGSpecDesc | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> KeyArray:\n\u001b[32m    224\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Create a legacy PRNG key given an integer seed.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m    226\u001b[39m \u001b[33;03m  This function produces old-style legacy PRNG keys, which are arrays\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m \u001b[33;03m    and ``fold_in``.\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _return_prng_keys(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43m_key\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPRNGKey\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/STG3A/deeperorwider/.venv/lib/python3.11/site-packages/jax/_src/random.py:197\u001b[39m, in \u001b[36m_key\u001b[39m\u001b[34m(ctor_name, seed, impl_spec)\u001b[39m\n\u001b[32m    194\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    195\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m accepts a scalar seed, but was given a PRNG key.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.ndim(seed):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    198\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m accepts a scalar seed, but was given an array of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.shape(seed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != (). Use jax.vmap for batching\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prng.random_seed(seed, impl=impl)\n",
      "\u001b[31mTypeError\u001b[39m: PRNGKey accepts a scalar seed, but was given an array of shape (2,) != (). Use jax.vmap for batching"
     ]
    }
   ],
   "source": [
    "# --- Main Experiment Loop ---\n",
    "key_seed = RANDOM_SEED\n",
    "mean_eigenvalues_per_L = []\n",
    "std_eigenvalues_per_L = []\n",
    "inf_norms_per_L = []\n",
    "\n",
    "print(\"Starting the analysis of the empirical K3 tensor...\")\n",
    "for L in L_VALUES:\n",
    "    print(f\"Computing for L = {L} layers (M={M})...\")\n",
    "\n",
    "    # Initialization\n",
    "    key = jax.random.PRNGKey(key_seed)\n",
    "    data_key, net_key = jax.random.split(key)\n",
    "    weights = init_network(net_key, L, D_IN, M)\n",
    "    data = generate_data(data_key, N, D_IN)\n",
    "    \n",
    "    # Forward pass to get necessary values\n",
    "    feature_maps, sigma_derivatives = compute_features_and_derivatives(weights, data)\n",
    "\n",
    "    # Instantiate the K3 computer\n",
    "    k3_computer = Kernel3Empirical(weights, sigma_derivatives, feature_maps)\n",
    "\n",
    "    # Compute the full K3 tensor\n",
    "    k3_tensor = np.zeros((N, N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            for k in range(j, N):\n",
    "                val = k3_computer.kernel3(i, j, k)\n",
    "                # Apply symmetry\n",
    "                k3_tensor[i, j, k] = k3_tensor[i, k, j] = k3_tensor[j, i, k] = \\\n",
    "                k3_tensor[j, k, i] = k3_tensor[k, i, j] = k3_tensor[k, j, i] = val\n",
    "\n",
    "    # Analyze the tensor\n",
    "    inf_norm = np.max(np.abs(k3_tensor))\n",
    "    inf_norms_per_L.append(inf_norm)\n",
    "\n",
    "    all_slice_eigenvalues = []\n",
    "    for k in range(N):\n",
    "        slice_matrix = k3_tensor[:, :, k]\n",
    "        eigenvalues = np.linalg.eigvalsh(slice_matrix)\n",
    "        all_slice_eigenvalues.append(eigenvalues)\n",
    "    \n",
    "    all_slice_eigenvalues = np.array(all_slice_eigenvalues)\n",
    "    mean_eigenvalues_per_L.append(np.mean(all_slice_eigenvalues, axis=0))\n",
    "    std_eigenvalues_per_L.append(np.std(all_slice_eigenvalues, axis=0))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "mean_eigenvalues_per_L = np.array(mean_eigenvalues_per_L)\n",
    "std_eigenvalues_per_L = np.array(std_eigenvalues_per_L)\n",
    "inf_norms_per_L = np.array(inf_norms_per_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25756629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting ---\n",
    "plot_suffix = f\"finite_M{M}_N{N}_D{D_IN}\"\n",
    "\n",
    "# Plot 1: Infinity norm vs. L\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f\"Infinity Norm of K3 Tensor vs. Depth (Finite Width M={M})\")\n",
    "plt.plot(L_VALUES, inf_norms_per_L, 'o-')\n",
    "plt.xlabel(\"Number of Layers (L)\")\n",
    "plt.ylabel(\"Infinity Norm\")\n",
    "plt.xticks(L_VALUES)\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.savefig(os.path.join(PATH_TO_PLOTS, f\"k3_inf_norm_vs_L_{plot_suffix}.png\"))\n",
    "print(f\"K3 infinity norm plot saved to {PATH_TO_PLOTS}/k3_inf_norm_vs_L_{plot_suffix}.png\")\n",
    "\n",
    "# Plot 2: Mean eigenvalues vs. L\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.title(f\"Mean Eigenvalues of K3 Tensor Slices vs. Depth (Finite Width M={M})\")\n",
    "for k in range(N):\n",
    "    means = mean_eigenvalues_per_L[:, k]\n",
    "    stds = std_eigenvalues_per_L[:, k]\n",
    "    p = plt.plot(L_VALUES, means, 'o-', label=f'λ_{k+1}')\n",
    "    plt.fill_between(L_VALUES, means - stds, means + stds, alpha=0.2, color=p[0].get_color())\n",
    "\n",
    "plt.xlabel(\"Number of Layers (L)\")\n",
    "plt.ylabel(\"Mean Eigenvalue of Slice\")\n",
    "plt.yscale('symlog')\n",
    "plt.xticks(L_VALUES)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.legend(title=\"Eigenvalue Order\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.savefig(os.path.join(PATH_TO_PLOTS, f\"k3_slice_eigenvalues_vs_L_{plot_suffix}.png\"))\n",
    "print(f\"K3 slice eigenvalues plot saved to {PATH_TO_PLOTS}/k3_slice_eigenvalues_vs_L_{plot_suffix}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Data ---\n",
    "output_data = {\n",
    "    'l_values': L_VALUES,\n",
    "    'm_value': M,\n",
    "    'inf_norms': inf_norms_per_L,\n",
    "    'mean_eigenvalues': mean_eigenvalues_per_L,\n",
    "    'std_eigenvalues': std_eigenvalues_per_L,\n",
    "    'config': {'N': N, 'D_IN': D_IN, 'RANDOM_SEED': RANDOM_SEED}\n",
    "}\n",
    "np.save(os.path.join(PATH_TO_DATA, f\"k3_analysis_{plot_suffix}.npy\"), output_data)\n",
    "print(f\"K3 analysis data saved to {PATH_TO_DATA}/k3_analysis_{plot_suffix}.npy\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
