{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import neural_tangents as nt\n",
    "from neural_tangents import stax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b902ca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "N = 100  # Number of data points\n",
    "D_IN = 10  # Input dimension\n",
    "M = 100  # Width of the network\n",
    "L_VALUES = jnp.linspace(10, 100, 20).astype(int)\n",
    "RANDOM_SEED = 42\n",
    "N_experiments = 10  # For eigenvalue mean computation\n",
    "\n",
    "\n",
    "PATH_TO_PLOTS = \"/home/janis/STG3A/deeperorwider/experiments/plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c4906",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_data(key, n_samples, n_features):\n",
    "    \"\"\"Generates random data and normalizes it.\"\"\"\n",
    "    data = random.normal(key, (n_samples, n_features))\n",
    "    norm = jnp.linalg.norm(data, axis=1, keepdims=True)\n",
    "    return data / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17773a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = random.PRNGKey(RANDOM_SEED)\n",
    "eigenvalues_per_L = []\n",
    "\n",
    "print(\"Starting NTK eigenvalue analysis using neural-tangents...\")\n",
    "for L in L_VALUES:\n",
    "    print(f\"Computing for L = {L} layers...\")\n",
    "    eigenvalues_experiments = []\n",
    "    \n",
    "    for exp in range(N_experiments):\n",
    "        key, data_key, model_key = random.split(key, 3)\n",
    "        data = generate_data(data_key, N, D_IN)\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(stax.Dense(M, W_std=jnp.sqrt(2), b_std=0.0, parameterization='ntk'))\n",
    "        layers.append(stax.Relu())\n",
    "        \n",
    "        for _ in range(L - 1):\n",
    "            layers.append(stax.Dense(M, W_std=jnp.sqrt(2), b_std=0.0, parameterization='ntk'))\n",
    "            layers.append(stax.Relu())\n",
    "            \n",
    "        layers.append(stax.Dense(1, W_std=jnp.sqrt(2), b_std=0.0, parameterization='ntk'))\n",
    "        \n",
    "        init_fn, apply_fn, _ = stax.serial(*layers)\n",
    "        params = init_fn(model_key, data.shape)[1]\n",
    "\n",
    "        ntk_fn = nt.empirical_ntk_fn(apply_fn)\n",
    "        k2_matrix = ntk_fn(data, None, params)\n",
    "        \n",
    "        eigenvalues = jnp.linalg.eigvalsh(k2_matrix)\n",
    "        eigenvalues_experiments.append(eigenvalues)\n",
    "    \n",
    "    # Take mean over experiments\n",
    "    mean_eigenvalues = jnp.mean(jnp.stack(eigenvalues_experiments), axis=0)\n",
    "    eigenvalues_per_L.append(mean_eigenvalues)\n",
    "\n",
    "if not os.path.exists(PATH_TO_PLOTS):\n",
    "    os.makedirs(PATH_TO_PLOTS)\n",
    "\n",
    "# Plot eigenvalue histograms\n",
    "n_L = len(L_VALUES)\n",
    "fig, axes = plt.subplots(1, n_L, figsize=(5 * n_L, 4), sharey=True)\n",
    "fig.suptitle(f'Histogram of Mean Empirical NTK Eigenvalues (width M={M}, {N_experiments} experiments)')\n",
    "for i, L in enumerate(L_VALUES):\n",
    "    ax = axes[i]\n",
    "    ax.hist(eigenvalues_per_L[i], bins='auto', density=True)\n",
    "    ax.set_title(f\"Depth L = {L}\")\n",
    "    ax.set_xlabel(\"Eigenvalue\")\n",
    "    ax.set_yscale('log') # for relu\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(PATH_TO_PLOTS + \"/ntk_empirical_eigenvalue_histograms_finite.png\")\n",
    "print(\"Saved eigenvalue histograms to \" + PATH_TO_PLOTS + \"/ntk_empirical_eigenvalue_histograms_finite.png\")\n",
    "\n",
    "# Plot k-th eigenvalue vs L\n",
    "eigenvalues_per_L = np.array(eigenvalues_per_L)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f\"Top D_IN NTK Eigenvalues vs Network Depth (width M={M}, {N_experiments} experiments)\")\n",
    "'''\n",
    "for k in range(1, min(2*D_IN,N)):\n",
    "    plt.plot(L_VALUES, eigenvalues_per_L[:, -k], 'o-', label=f'λ_{k}')\n",
    "'''\n",
    "plt.plot(L_VALUES, eigenvalues_per_L[:, 0], 'o--', label=f'λ_min')\n",
    "\n",
    "plt.xlabel(\"Number of Layers (L)\")\n",
    "plt.ylabel(\"Mean Eigenvalue\")\n",
    "# plt.yscale('log')\n",
    "plt.xticks(L_VALUES)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.savefig(PATH_TO_PLOTS + \"/kth_eigenvalue_vs_L_empirical_finite.png\")\n",
    "print(\"Saved k-th eigenvalue plot to \" + PATH_TO_PLOTS + \"/kth_eigenvalue_vs_L_empirical_finite.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e508069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59d324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa07d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
